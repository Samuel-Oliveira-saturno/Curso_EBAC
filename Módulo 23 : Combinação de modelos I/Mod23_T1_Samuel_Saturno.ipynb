{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/media/logo/newebac_logo_black_half.png\" alt=\"ebac-logo\">\n",
        "\n",
        "---\n",
        "\n",
        "# **Módulo 23** | Combinação de modelos I\n",
        "Caderno de **exercício 01**<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Discente: Samuel Saturno\n"
      ],
      "metadata": {
        "id": "IQZl-knkK6k0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font  color=\"blue\"><strong>1. Monte um passo a passo para o Bagging</strong></font></h3>\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 1: Entendimento do Bagging</strong></font></h5>\n",
        "\n",
        "<h5><font  color=\"\"><i>Bagging é uma técnica de ensemble que combina múltiplos modelos de aprendizado de máquina para melhorar o desempenho preditivo. Ele funciona treinando vários modelos em subconjuntos aleatórios dos dados de treinamento e, em seguida, combinando as previsões desses modelos para produzir uma única previsão.</font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 2: Preparação dos Dados</strong></font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><i>Gerenciamento dos dados tratando os valores ausentes, codificando as variáveis categóricas. Organizar o conjunto dados em duas partes um de treinamento e um conjunto de teste. O conjunto de treinamento será usado para treinar os modelos e o conjunto de teste será usado para avaliar o desempenho do modelo final.\n",
        ".</font></h5>\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 3: Implementação do Bagging</strong></font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><i>\n",
        "\n",
        "\n",
        "* Bootstraping: Para cada modelo no ensemble, amostrar aleatoriamente (com substituição) um conjunto de dados do conjunto de treinamento original. Essa amostragem cria vários conjuntos de treinamento diferentes.\n",
        "\n",
        "\n",
        "* Treinamento dos Modelos: Treine um modelo em cada um dos conjuntos de dados amostrados.\n",
        "* Previsões: Faça previsões com cada modelo para o conjunto de teste.\n",
        "* Combinação das Previsões: Combine as previsões de todos os modelos. Para problemas de classificação, pode-se usar a moda (valor mais frequente) das previsões como a previsão final. Para problemas de regressão, a média das previsões pode ser usada.\n",
        "* Avaliação do Desempenho: Avalie o desempenho do modelo final usando métricas apropriadas para o tipo de problema (por exemplo, precisão, recall, F1-score para classificação; erro quadrático médio para regressão).</font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 4: Ajuste de Parâmetros Opcionais</strong></font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><i>\n",
        "\n",
        "* Número de Modelos: Experimente diferentes números de modelos no ensemble para encontrar o equilíbrio entre viés e variância.\n",
        "\n",
        "\n",
        "* Profundidade do Modelo: Dependendo do tipo de modelo que está sendo usado (por exemplo, árvores de decisão), ajuste a profundidade do modelo para evitar overfitting.\n",
        "\n",
        "\n",
        "* Tamanho da Amostra Bootstrap: Experimente diferentes tamanhos de amostra para a técnica de bootstrap e avalie seu impacto no desempenho do modelo.</font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 5: Validação Cruzada (Opcional)</strong></font></h5>\n",
        "\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><i>K-fold Cross Validation: Para uma avaliação mais robusta do desempenho do modelo, você pode usar validação cruzada k-fold. Isso envolve dividir os dados em k partes iguais, treinar o modelo em k-1 partes e avaliá-lo na parte restante. Repita esse processo k vezes e calcule a média das métricas de desempenho.</font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 6: Avaliação do Desempenho Final</strong></font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><i>Avaliação no Conjunto de Teste: Após ajustar e validar o modelo, avalie-o no conjunto de teste final para obter uma estimativa realista do desempenho do modelo em dados não vistos.</font></h5>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><strong>Passo 7: Implementação e Otimização</strong></font></h5>\n",
        "\n",
        "<h5><font  color=\"\"><i>\n",
        "\n",
        "* Implementação em uma Linguagem de Programação:\n",
        " Implemente o algoritmo de Bagging em uma linguagem de programação, como Python ou R, utilizando bibliotecas de aprendizado de máquina, como scikit-learn ou TensorFlow.\n",
        "\n",
        "* Otimização de Desempenho: Experimente técnicas de otimização de desempenho, como paralelização, para reduzir o tempo de treinamento do modelo.</font></h5>\n",
        "\n",
        "<h5><font  color=\"\"><strong>Referências Bibliográticas (visto em 17/04/2024)</strong></font></h5>\n",
        "\n",
        "<h6><font  color=\"blue\"><strong>Sites:</strong></font></h6>\n",
        "\n",
        "https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosted-trees\n",
        "\n",
        "\n",
        "https://www.ibm.com/br-pt/topics/bagging"
      ],
      "metadata": {
        "id": "Sfee7KzBDj_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font  color=\"blue\"><strong>2. Explique com suas palavras o Bagging</strong></font></h3>\n",
        "\n",
        "\n",
        "<h5><font  color=\"\"><i> Bagging, conhecido como agregação de bootstrap, é o método de aprendizado por agrupamento, comumente usado para reduzir a variância em um conjunto de dados com ruídos. No bagging, uma amostra aleatória de dados em um conjunto de treinamento é selecionada com substituição, o que significa que os pontos de dados individuais podem ser escolhidos mais de uma vez. Após gerar várias amostras de dados, esses modelos fracos são então treinados de forma independente e de acordo com o tipo de tarefa, por exemplo, regressão ou classificação. A média ou a maioria dessas previsões resulta em uma estimativa mais precisa.</i></font></h5>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vn0VJluJHDzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font  color=\"blue\"><strong>3.(Opcional) Implementar em python o código do Bagging </strong></font></h3> <br>\n",
        "\n",
        "\n",
        "<h3><font  color=\"\"><strong>\n",
        "\n",
        "* Bootstrap\n",
        "* Modelagem\n",
        "* Agregação\n",
        "</strong></font></h3> <br>\n"
      ],
      "metadata": {
        "id": "sA_KavbVJcRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font  color=\"\">\n",
        "O script abaixo implementa e avalia um classificador de Bagging usando árvores de decisão como modelos base, e usa o conjunto de dados Iris como exemplo. O objetivo é calcular a acurácia do classificador no conjunto de teste para avaliar seu desempenho.\n",
        "</font></h3> <br>\n"
      ],
      "metadata": {
        "id": "GcdwN-K77ybU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as Bibliotecas\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class BaggingClassifier:\n",
        "    def __init__(self, n_estimators=10, max_samples=1.0):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_samples = max_samples\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Bootstrap: amostragem aleatória com substituição\n",
        "            indices = np.random.choice(len(X), size=int(self.max_samples * len(X)), replace=True)\n",
        "            X_bootstrap = X[indices]\n",
        "            y_bootstrap = y[indices]\n",
        "\n",
        "            # Modelagem: treinamento do modelo em cada amostra bootstrap\n",
        "            model = DecisionTreeClassifier()\n",
        "            model.fit(X_bootstrap, y_bootstrap)\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Agregação: combinação das previsões de todos os modelos\n",
        "        predictions = np.array([model.predict(X) for model in self.models])\n",
        "        return np.mean(predictions, axis=0).round().astype(int)\n",
        "\n",
        "# Carregar dataset de exemplo (iris dataset)\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir o dataset em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inicialização do BaggingClassifier com 5 modelos e máximo de amostras 0.8\n",
        "bagging_clf = BaggingClassifier(n_estimators=5, max_samples=0.8)\n",
        "\n",
        "# Treinamento do BaggingClassifier\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "predictions = bagging_clf.predict(X_test)\n",
        "\n",
        "# Avaliação do desempenho\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Acurácia:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJLr8gJQJoN6",
        "outputId": "295490cb-5943-4851-c3c0-776446318d27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação obtida no site do scikit-learn\n",
        "\n",
        "# Importando as Bibliotecas\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "\n",
        "# Gerando dados sintéticos com a função make_hastie_10_2\n",
        "# A função retorna uma matriz X e um vetor y simulados\n",
        "# random_state=0 garante que os mesmos dados sejam gerados sempre que o código for executado\n",
        "X, y = make_hastie_10_2(random_state=0)\n",
        "\n",
        "# Dividindo os dados em conjunto de treinamento e teste\n",
        "# Os primeiros 2000 exemplos são usados para treinamento e o restante para teste\n",
        "X_train, X_test = X[:2000], X[2000:]\n",
        "y_train, y_test = y[:2000], y[2000:]\n",
        "\n",
        "# Inicializando o classificador HistGradientBoostingClassifier com max_iter=100\n",
        "# O classificador é treinado usando os dados de treinamento\n",
        "clf = HistGradientBoostingClassifier(max_iter=100).fit(X_train, y_train)\n",
        "\n",
        "# Calculando a acurácia do classificador nos dados de teste\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(\"Acurácia:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-nuP2_4NV5k",
        "outputId": "3bd1df88-935e-4446-85e5-a42f33b35ea1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.8965\n"
          ]
        }
      ]
    }
  ]
}